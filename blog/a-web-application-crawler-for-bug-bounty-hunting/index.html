<!DOCTYPE html><html lang="en"><head><meta charset="utf-8" /><meta http-equiv="X-UA-Compatible" content="IE=edge" /><meta name="viewport" content="width=device-width, initial-scale=1" /><link rel="stylesheet" href="/css/template.css?version=2.0.1" /><link rel="shortcut icon" href="/img/favicon.svg?version=2.0.1" type="image/svg+xml" /> <script src="/js/template.js?version=2.0.1"></script><meta name="theme-color" content="#e6e6e6" media="(prefers-color-scheme: light)" /><meta name="theme-color" content="#e6e6e6" media="(prefers-color-scheme: dark)" /><title>A web application crawler for bug bounty hunting</title><meta property="og:title" content="A web application crawler for bug bounty hunting"><meta name="description" itemprop="description" content="Not Your Average Web Crawler (NYAWC) is a Python package that enables you to crawl web applications for requests instead of URL's. With NYAWC you can execute your malicious payload on all in-scope requests of a web application."><meta property="og:description" content="Not Your Average Web Crawler (NYAWC) is a Python package that enables you to crawl web applications for requests instead of URL's. With NYAWC you can execute your malicious payload on all in-scope requests of a web application."><meta name="keywords" content="nyawc, web, application, crawler, spider, crawling, bot, hacking, bug, bounty, open, source, python"><meta name="language" content="english"><meta name="author" itemprop="creator" content="Tijme Gommers"><meta name="robots" content="index, follow"><meta name="distribution" content="global"><meta name="copyright" content="Copyright © 2024 Tijme Gommers. All rights reserved."><link rel="alternate" type="application/rss+xml" title="Atom" href="/feeds/atom.xml"></head><body><div class="navbar-wrapper mb-4"><div class="container"><div class="row justify-content-center"><div class="col-12 col-sm-12 col-md-12 col-lg-11 col-xl-8 col-xll-6"><nav class="navbar navbar-expand"><div class="collapse navbar-collapse"><ul class="navbar-nav me-auto"><li class="nav-item"> <a href="/" target="_self" class="nav-link"> <span>Posts</span> </a></li><li class="nav-item"> <a href="/about/" target="_self" class="nav-link"> <span>About</span> </a></li><li class="nav-item"> <a href="/donate/" target="_self" class="nav-link"> <span>Donate</span> </a></li></ul><ul class="navbar-nav"><li class="nav-item"> <a href="https://twitter.com/tijme" target="_blank" rel="noopener noreferrer" class="nav-link"> <span><span class="icon"> <svg><use xlink:href="/img/icons.svg#twitter"/></svg> </span></span> </a></li><li class="nav-item d-none d-sm-block"> <a href="https://www.linkedin.com/in/tijme/" target="_blank" rel="noopener noreferrer" class="nav-link"> <span><span class="icon"> <svg><use xlink:href="/img/icons.svg#linkedin"/></svg> </span></span> </a></li><li class="nav-item d-none d-sm-block"> <a href="https://github.com/tijme/" target="_blank" rel="noopener noreferrer" class="nav-link"> <span><span class="icon"> <svg><use xlink:href="/img/icons.svg#github"/></svg> </span></span> </a></li><li class="nav-item d-none d-sm-block"> <a href="/feeds/atom.xml" target="_blank" class="nav-link"> <span><span class="icon"> <svg><use xlink:href="/img/icons.svg#rss"/></svg> </span></span> </a></li></ul></div></nav></div></div></div></div><div class="container"><div class="row justify-content-center"><div class="col-12 col-sm-12 col-md-12 col-lg-11 col-xl-8 col-xll-6"><article class="container-fluid"><h1 class="mb-2">A web application crawler for bug bounty hunting</h1><p class="mb-2 text-muted">Posted on <time datetime="2017-04-28T00:00:00+00:00">28 April 2017</time> by Tijme Gommers.</p><p>Not Your Average Web Crawler (<a href="https://github.com/tijme/not-your-average-web-crawler" target="_blank" rel="noopener noreferrer">N.Y.A.W.C</a>) is a web application crawler for vulnerability scanning. It crawls every request in a specified scope and keeps track of the request/response data. I developed N.Y.A.W.C because I needed a good open-source Python crawler that enabled me to modify requests on the go for my <a href="https://github.com/tijme/angularjs-csti-scanner" target="_blank" rel="noopener noreferrer">AngularJS CSTI scanner</a>.</p><h3 id="crawling-flow">Crawling flow</h3><p>The crawler is multi-threaded but you don’t have to worry about any of the multi threading yourself. To give you a better idea of the crawling flow I added the diagram below.</p><ol><li>You can define your startpoint (a request) and the crawling scope and then start the crawler.</li><li>The crawler repeatedly starts the first request in the queue until <code class="language-plaintext highlighter-rouge">max threads</code> is reached.</li><li>The crawler adds all requests found in the response to the end of the queue (except duplicates).</li><li>The crawler goes back to step #2 to spawn new requests repeatedly until <code class="language-plaintext highlighter-rouge">max threads</code> is reached.</li></ol><p>Please note that if the queue is empty and all crawler threads are finished, the crawler will stop.</p><p><a href="/img/a-web-application-crawler-for-bug-bounty-hunting/nyawc-flow.svg" target="_blank" rel="noopener noreferrer" data-lightbox="nyawc-flow" data-title="Crawling flow of NYAWC"><img src="/img/a-web-application-crawler-for-bug-bounty-hunting/nyawc-flow.svg" title="Crawling flow of NYAWC" alt="Crawling flow of NYAWC" /></a></p><p>There are several hooks in the code that you can use to, for example, tamper form data before it is posted. Check the <a href="https://tijme.github.io/not-your-average-web-crawler/latest/options_callbacks.html" target="_blank" rel="noopener noreferrer">documentation</a> for more information about those hooks.</p><h3 id="installation">Installation</h3><p>First make sure you’re on Python 2.7/3.3 or higher. After that install N.Y.A.W.C via PyPi using the command below.</p><figure class="highlight"><pre><code class="language-bash" data-lang="bash">pip <span class="nb">install</span> <span class="nt">--upgrade</span> nyawc</code></pre></figure><p>The kitchen sink code sample below can be used to get the crawler up and running within a few minutes. If you like it, check out the <a href="https://tijme.github.io/not-your-average-web-crawler/" target="_blank" rel="noopener noreferrer">documentation</a> to get started on implementing your own exploits.</p><figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># -*- coding: utf-8 -*-
</span>
<span class="c1"># MIT License
#
# Copyright (c) 2017 Tijme Gommers
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
</span>
<span class="kn">from</span> <span class="nn">nyawc.Options</span> <span class="kn">import</span> <span class="n">Options</span>
<span class="kn">from</span> <span class="nn">nyawc.QueueItem</span> <span class="kn">import</span> <span class="n">QueueItem</span>
<span class="kn">from</span> <span class="nn">nyawc.Crawler</span> <span class="kn">import</span> <span class="n">Crawler</span>
<span class="kn">from</span> <span class="nn">nyawc.CrawlerActions</span> <span class="kn">import</span> <span class="n">CrawlerActions</span>
<span class="kn">from</span> <span class="nn">nyawc.http.Request</span> <span class="kn">import</span> <span class="n">Request</span>
<span class="kn">from</span> <span class="nn">requests.auth</span> <span class="kn">import</span> <span class="n">HTTPBasicAuth</span>

<span class="k">def</span> <span class="nf">cb_crawler_before_start</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Crawler started."</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">cb_crawler_after_finish</span><span class="p">(</span><span class="n">queue</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Crawler finished."</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Found "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">queue</span><span class="p">.</span><span class="n">get_all</span><span class="p">(</span><span class="n">QueueItem</span><span class="p">.</span><span class="n">STATUS_FINISHED</span><span class="p">)))</span> <span class="o">+</span> <span class="s">" requests."</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">queue_item</span> <span class="ow">in</span> <span class="n">queue</span><span class="p">.</span><span class="n">get_all</span><span class="p">(</span><span class="n">QueueItem</span><span class="p">.</span><span class="n">STATUS_FINISHED</span><span class="p">).</span><span class="n">values</span><span class="p">():</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"["</span> <span class="o">+</span> <span class="n">queue_item</span><span class="p">.</span><span class="n">request</span><span class="p">.</span><span class="n">method</span> <span class="o">+</span> <span class="s">"] "</span> <span class="o">+</span> <span class="n">queue_item</span><span class="p">.</span><span class="n">request</span><span class="p">.</span><span class="n">url</span> <span class="o">+</span> <span class="s">" (PostData: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">queue_item</span><span class="p">.</span><span class="n">request</span><span class="p">.</span><span class="n">data</span><span class="p">)</span> <span class="o">+</span> <span class="s">")"</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">cb_request_before_start</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span> <span class="n">queue_item</span><span class="p">):</span>
    <span class="c1"># return CrawlerActions.DO_SKIP_TO_NEXT
</span>    <span class="c1"># return CrawlerActions.DO_STOP_CRAWLING
</span>
    <span class="k">return</span> <span class="n">CrawlerActions</span><span class="p">.</span><span class="n">DO_CONTINUE_CRAWLING</span>

<span class="k">def</span> <span class="nf">cb_request_after_finish</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span> <span class="n">queue_item</span><span class="p">,</span> <span class="n">new_queue_items</span><span class="p">):</span>
    <span class="n">percentage</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">queue</span><span class="p">.</span><span class="n">get_progress</span><span class="p">()))</span>
    <span class="n">total_requests</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">queue</span><span class="p">.</span><span class="n">count_total</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"At "</span> <span class="o">+</span> <span class="n">percentage</span> <span class="o">+</span> <span class="s">"% of "</span> <span class="o">+</span> <span class="n">total_requests</span> <span class="o">+</span> <span class="s">" requests (["</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">queue_item</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">status_code</span><span class="p">)</span> <span class="o">+</span> <span class="s">"] "</span> <span class="o">+</span> <span class="n">queue_item</span><span class="p">.</span><span class="n">request</span><span class="p">.</span><span class="n">url</span> <span class="o">+</span> <span class="s">")."</span><span class="p">)</span>

    <span class="c1"># return CrawlerActions.DO_STOP_CRAWLING
</span>    <span class="k">return</span> <span class="n">CrawlerActions</span><span class="p">.</span><span class="n">DO_CONTINUE_CRAWLING</span>

<span class="k">def</span> <span class="nf">cb_request_in_thread_before_start</span><span class="p">(</span><span class="n">queue_item</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="k">def</span> <span class="nf">cb_request_in_thread_after_finish</span><span class="p">(</span><span class="n">queue_item</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="k">def</span> <span class="nf">cb_request_on_error</span><span class="p">(</span><span class="n">queue_item</span><span class="p">,</span> <span class="n">message</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"[error] "</span> <span class="o">+</span> <span class="n">message</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">cb_form_before_autofill</span><span class="p">(</span><span class="n">queue_item</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">form_data</span><span class="p">):</span>
    <span class="c1"># return CrawlerActions.DO_NOT_AUTOFILL_FORM
</span>
    <span class="k">return</span> <span class="n">CrawlerActions</span><span class="p">.</span><span class="n">DO_AUTOFILL_FORM</span>

<span class="k">def</span> <span class="nf">cb_form_after_autofill</span><span class="p">(</span><span class="n">queue_item</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">form_data</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="c1"># Declare the options
</span><span class="n">options</span> <span class="o">=</span> <span class="n">Options</span><span class="p">()</span>

<span class="c1"># Callback options (https://tijme.github.io/not-your-average-web-crawler/latest/options_callbacks.html)
</span><span class="n">options</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">crawler_before_start</span> <span class="o">=</span> <span class="n">cb_crawler_before_start</span> <span class="c1"># Called before the crawler starts crawling. Default is a null route.
</span><span class="n">options</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">crawler_after_finish</span> <span class="o">=</span> <span class="n">cb_crawler_after_finish</span> <span class="c1"># Called after the crawler finished crawling. Default is a null route.
</span><span class="n">options</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">request_before_start</span> <span class="o">=</span> <span class="n">cb_request_before_start</span> <span class="c1"># Called before the crawler starts a new request. Default is a null route.
</span><span class="n">options</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">request_after_finish</span> <span class="o">=</span> <span class="n">cb_request_after_finish</span> <span class="c1"># Called after the crawler finishes a request. Default is a null route.
</span><span class="n">options</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">request_in_thread_before_start</span> <span class="o">=</span> <span class="n">cb_request_in_thread_before_start</span> <span class="c1"># Called in the crawling thread (when it started). Default is a null route.
</span><span class="n">options</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">request_in_thread_after_finish</span> <span class="o">=</span> <span class="n">cb_request_in_thread_after_finish</span> <span class="c1"># Called in the crawling thread (when it finished). Default is a null route.
</span><span class="n">options</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">request_on_error</span> <span class="o">=</span> <span class="n">cb_request_on_error</span> <span class="c1"># Called if a request failed. Default is a null route.
</span><span class="n">options</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">form_before_autofill</span> <span class="o">=</span> <span class="n">cb_form_before_autofill</span> <span class="c1"># Called before the crawler autofills a form. Default is a null route.
</span><span class="n">options</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">form_after_autofill</span> <span class="o">=</span> <span class="n">cb_form_after_autofill</span> <span class="c1"># Called after the crawler autofills a form. Default is a null route.
</span>
<span class="c1"># Scope options (https://tijme.github.io/not-your-average-web-crawler/latest/options_crawling_scope.html)
</span><span class="n">options</span><span class="p">.</span><span class="n">scope</span><span class="p">.</span><span class="n">protocol_must_match</span> <span class="o">=</span> <span class="bp">False</span> <span class="c1"># Only crawl pages with the same protocol as the startpoint (e.g. only https). Default is False.
</span><span class="n">options</span><span class="p">.</span><span class="n">scope</span><span class="p">.</span><span class="n">subdomain_must_match</span> <span class="o">=</span> <span class="bp">True</span> <span class="c1"># Only crawl pages with the same subdomain as the startpoint. If the startpoint is not a subdomain, no subdomains will be crawled. Default is True.
</span><span class="n">options</span><span class="p">.</span><span class="n">scope</span><span class="p">.</span><span class="n">hostname_must_match</span> <span class="o">=</span> <span class="bp">True</span> <span class="c1"># Only crawl pages with the same hostname as the startpoint (e.g. only `finnwea`). Default is True.
</span><span class="n">options</span><span class="p">.</span><span class="n">scope</span><span class="p">.</span><span class="n">tld_must_match</span> <span class="o">=</span> <span class="bp">True</span> <span class="c1"># Only crawl pages with the same tld as the startpoint (e.g. only `.com`). Default is True.
</span><span class="n">options</span><span class="p">.</span><span class="n">scope</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># The maximum search depth. 0 only crawls the start request. 1 will also crawl all the requests found on the start request. 2 goes one level deeper, and so on. Default is None (unlimited).
</span><span class="n">options</span><span class="p">.</span><span class="n">scope</span><span class="p">.</span><span class="n">request_methods</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1"># The request methods to crawl. Default is all request methods
</span>    <span class="n">Request</span><span class="p">.</span><span class="n">METHOD_GET</span><span class="p">,</span>
    <span class="n">Request</span><span class="p">.</span><span class="n">METHOD_POST</span><span class="p">,</span>
    <span class="n">Request</span><span class="p">.</span><span class="n">METHOD_PUT</span><span class="p">,</span>
    <span class="n">Request</span><span class="p">.</span><span class="n">METHOD_DELETE</span><span class="p">,</span>
    <span class="n">Request</span><span class="p">.</span><span class="n">METHOD_OPTIONS</span><span class="p">,</span>
    <span class="n">Request</span><span class="p">.</span><span class="n">METHOD_HEAD</span>
<span class="p">]</span>

<span class="c1"># Identity options (https://tijme.github.io/not-your-average-web-crawler/latest/options_crawling_identity.html)
</span><span class="n">options</span><span class="p">.</span><span class="n">identity</span><span class="p">.</span><span class="n">auth</span> <span class="o">=</span> <span class="n">HTTPBasicAuth</span><span class="p">(</span><span class="s">'user'</span><span class="p">,</span> <span class="s">'pass'</span><span class="p">)</span> <span class="c1"># Or any other authentication (http://docs.python-requests.org/en/master/user/authentication/). Default is None.
</span><span class="n">options</span><span class="p">.</span><span class="n">identity</span><span class="p">.</span><span class="n">cookies</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'tasty_cookie'</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="s">'yum'</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s">'finnwea.com'</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s">'/cookies'</span><span class="p">)</span>
<span class="n">options</span><span class="p">.</span><span class="n">identity</span><span class="p">.</span><span class="n">cookies</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'gross_cookie'</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="s">'blech'</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s">'finnwea.com'</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s">'/elsewhere'</span><span class="p">)</span>
<span class="n">options</span><span class="p">.</span><span class="n">identity</span><span class="p">.</span><span class="n">proxies</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># No authentication
</span>    <span class="c1"># 'http': 'http://host:port',
</span>    <span class="c1"># 'https': 'http://host:port',
</span>
    <span class="c1"># Basic authentication
</span>    <span class="c1"># 'http': 'http://user:pass@host:port',
</span>    <span class="c1"># 'https': 'https://user:pass@host:port',
</span>
    <span class="c1"># SOCKS
</span>    <span class="c1"># 'http': 'socks5://user:pass@host:port',
</span>    <span class="c1"># 'https': 'socks5://user:pass@host:port'
</span><span class="p">}</span>
<span class="n">options</span><span class="p">.</span><span class="n">identity</span><span class="p">.</span><span class="n">headers</span><span class="p">.</span><span class="n">update</span><span class="p">({</span>
    <span class="s">"User-Agent"</span><span class="p">:</span> <span class="s">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"</span>
<span class="p">})</span>

<span class="c1"># Performance options (https://tijme.github.io/not-your-average-web-crawler/latest/options_performance.html)
</span><span class="n">options</span><span class="p">.</span><span class="n">performance</span><span class="p">.</span><span class="n">max_threads</span> <span class="o">=</span> <span class="mi">20</span> <span class="c1"># The maximum amount of simultaneous threads to use for crawling. Default is 40.
</span><span class="n">options</span><span class="p">.</span><span class="n">performance</span><span class="p">.</span><span class="n">request_timeout</span> <span class="o">=</span> <span class="mi">15</span> <span class="c1"># The request timeout in seconds (throws an exception if exceeded). Default is 30.
</span>
<span class="c1"># Routing options (https://tijme.github.io/not-your-average-web-crawler/latest/options_routing.html)
</span><span class="n">options</span><span class="p">.</span><span class="n">routing</span><span class="p">.</span><span class="n">minimum_threshold</span> <span class="o">=</span> <span class="mi">4</span> <span class="c1"># The minimum amount of requests to crawl (matching a certain route) before ignoring the rest. Default is 20.
</span><span class="n">options</span><span class="p">.</span><span class="n">routing</span><span class="p">.</span><span class="n">routes</span> <span class="o">=</span> <span class="p">[</span> 
    <span class="c1"># The regular expressions that represent routes that should not be cralwed more times than the minimum treshold. Default is an empty array.
</span>    <span class="s">"^(https?:\/\/)?(www\.)?finnwea\.com\/blog\/[^</span><span class="se">\n</span><span class="s"> \/]+\/$"</span> <span class="c1"># Only crawl /blog/{some-blog-alias} 4 times.
</span><span class="p">]</span>

<span class="c1"># Misc options (https://tijme.github.io/not-your-average-web-crawler/latest/options_misc.html)
</span><span class="n">options</span><span class="p">.</span><span class="n">misc</span><span class="p">.</span><span class="n">debug</span> <span class="o">=</span> <span class="bp">False</span> <span class="c1"># If debug is enabled extra information will be logged to the console. Default is False.
</span><span class="n">options</span><span class="p">.</span><span class="n">misc</span><span class="p">.</span><span class="n">verify_ssl_certificates</span> <span class="o">=</span> <span class="bp">True</span> <span class="c1"># If verification is enabled all SSL certificates will be checked for validity. Default is True.
</span><span class="n">options</span><span class="p">.</span><span class="n">misc</span><span class="p">.</span><span class="n">trusted_certificates</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># You can pass the path to a CA_BUNDLE file (.pem) or directory with certificates of trusted CAs. Default is None.
</span>
<span class="n">crawler</span> <span class="o">=</span> <span class="n">Crawler</span><span class="p">(</span><span class="n">options</span><span class="p">)</span>
<span class="n">crawler</span><span class="p">.</span><span class="n">start_with</span><span class="p">(</span><span class="n">Request</span><span class="p">(</span><span class="s">"https://finnwea.com/"</span><span class="p">))</span></code></pre></figure></article><footer class="text-center mt-5 mb-5"><div class="footer-links"> <a href="/"><span>Posts</span></a> <a href="/about/" target="_self"><span>About</span></a> <a href="/donate/" target="_self"><span>Donate</span></a> <a href="/responsible-disclosure/" target="_self"><span>Responsible Disclosure</span></a></div><p class="footer-copyright text-secondary"> Copyright &copy; 2024 Tijme Gommers. All rights reserved.</p><div class="footer-icons"><div class="padding"> <a href="https://twitter.com/tijme" target="_blank" rel="noopener nofollow"> <span><span class="icon"> <svg><use xlink:href="/img/icons.svg#twitter"/></svg> </span></span> </a></div><div class="padding"> <a href="https://github.com/tijme" target="_blank" rel="noopener nofollow"> <span><span class="icon"> <svg><use xlink:href="/img/icons.svg#github"/></svg> </span></span> </a></div><div class="padding"> <a href="https://www.linkedin.com/in/tijme" target="_blank" rel="noopener nofollow"> <span><span class="icon"> <svg><use xlink:href="/img/icons.svg#linkedin"/></svg> </span></span> </a></div></div></footer></div></div></div></body></html>
